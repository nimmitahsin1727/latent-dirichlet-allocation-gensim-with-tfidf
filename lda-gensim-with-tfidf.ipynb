{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LDA - Gensim with TF-IDF\n",
        "\n",
        "Here, I'm using LDA model from gensim. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOPoLTScu4V"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're in local machine, you should run this cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're in Google Colab, you should run this cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = \"<ENTER YOUR DRIVE PATH>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iW6IW_VNDJw"
      },
      "source": [
        "# Load Data\n",
        "Preprocessed training and testing data from \n",
        "[20-news-dataset-pre-processing](https://github.com/nimmitahsin1727/20-news-dataset-pre-processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1AubdN5uGOv"
      },
      "source": [
        "Reading TRAINING from CSV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "57OiI3tpuF8Y"
      },
      "outputs": [],
      "source": [
        "training_df = pd.read_csv(f'{BASE_PATH}training_df.csv') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebrTGRCCvGsj"
      },
      "source": [
        "Reading TESTING from CSV:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dMD2yGOGvJkK"
      },
      "outputs": [],
      "source": [
        "testing_df = pd.read_csv(f'{BASE_PATH}testing_df.csv') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCWaUQJfKSWq"
      },
      "source": [
        "Create data_words with training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bX8K5yK_J6Cw"
      },
      "outputs": [],
      "source": [
        "data_words = training_df.data.map(lambda doc: word_tokenize(doc)).values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XPhDJXRWcbl"
      },
      "source": [
        "**Bag of Words on the Data set**\n",
        "\n",
        "Create a dictionary from `data_words` containing the number of times a word appears in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbhA7QotULal",
        "outputId": "08a3bae0-b93c-4e8e-b51b-0bcad288aef2"
      },
      "outputs": [],
      "source": [
        "dictionary = corpora.Dictionary(data_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing some samples from dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 actively\n",
            "1 ama\n",
            "2 apr\n",
            "3 assistance\n",
            "4 away\n",
            "5 big\n",
            "6 bike\n",
            "7 board\n",
            "8 camp\n",
            "9 childish\n",
            "10 count\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqPO8s2TWSy-"
      },
      "source": [
        "**Gensim filter_extremes**\n",
        "\n",
        "***Filter out tokens that appear in***\n",
        "\n",
        "less than 15 documents (absolute number) or\n",
        "more than 0.5 documents (fraction of total corpus size, not absolute number)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xflYCHdyUggY"
      },
      "outputs": [],
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSbcIn2kWJXm"
      },
      "source": [
        "**Gensim doc2bow**\n",
        "\n",
        "For each document we create a dictionary reporting how many\n",
        "words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NJ8Jp_1aUty_"
      },
      "outputs": [],
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in data_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCIFEKZlWFTk"
      },
      "source": [
        "Preview Bag Of Words for our sample preprocessed document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-UMfDeHNVOUw"
      },
      "outputs": [],
      "source": [
        "bow_doc_123 = bow_corpus[123]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohTYek_MVhHM",
        "outputId": "c59b7432-37ae-4cbb-da8a-31c82769e81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word 4 (\"bike\") appears 1 time.\n",
            "Word 7 (\"dod\") appears 2 time.\n",
            "Word 19 (\"make\") appears 1 time.\n",
            "Word 26 (\"say\") appears 2 time.\n",
            "Word 33 (\"work\") appears 1 time.\n",
            "Word 45 (\"good\") appears 1 time.\n",
            "Word 48 (\"just\") appears 1 time.\n",
            "Word 51 (\"like\") appears 1 time.\n",
            "Word 82 (\"old\") appears 1 time.\n",
            "Word 114 (\"thing\") appears 1 time.\n",
            "Word 135 (\"replyto\") appears 1 time.\n",
            "Word 150 (\"check\") appears 1 time.\n",
            "Word 156 (\"damage\") appears 1 time.\n",
            "Word 184 (\"right\") appears 1 time.\n",
            "Word 187 (\"spot\") appears 1 time.\n",
            "Word 193 (\"today\") appears 1 time.\n",
            "Word 211 (\"difference\") appears 1 time.\n",
            "Word 228 (\"piece\") appears 1 time.\n",
            "Word 243 (\"wish\") appears 1 time.\n",
            "Word 274 (\"year\") appears 1 time.\n",
            "Word 276 (\"corner\") appears 2 time.\n",
            "Word 309 (\"confuse\") appears 1 time.\n",
            "Word 311 (\"delete\") appears 1 time.\n",
            "Word 321 (\"mike\") appears 1 time.\n",
            "Word 350 (\"hit\") appears 2 time.\n",
            "Word 351 (\"home\") appears 1 time.\n",
            "Word 381 (\"honda\") appears 1 time.\n",
            "Word 404 (\"day\") appears 1 time.\n",
            "Word 448 (\"list\") appears 1 time.\n",
            "Word 458 (\"okay\") appears 1 time.\n",
            "Word 464 (\"pull\") appears 1 time.\n",
            "Word 485 (\"foot\") appears 1 time.\n",
            "Word 487 (\"ground\") appears 1 time.\n",
            "Word 493 (\"previous\") appears 1 time.\n",
            "Word 553 (\"answer\") appears 1 time.\n",
            "Word 556 (\"change\") appears 1 time.\n",
            "Word 559 (\"couple\") appears 1 time.\n",
            "Word 575 (\"turn\") appears 1 time.\n",
            "Word 587 (\"feel\") appears 1 time.\n",
            "Word 591 (\"loss\") appears 1 time.\n",
            "Word 636 (\"michael\") appears 1 time.\n",
            "Word 687 (\"canada\") appears 1 time.\n",
            "Word 688 (\"contact\") appears 1 time.\n",
            "Word 689 (\"contribute\") appears 1 time.\n",
            "Word 734 (\"pipe\") appears 2 time.\n",
            "Word 764 (\"buck\") appears 1 time.\n",
            "Word 790 (\"happen\") appears 1 time.\n",
            "Word 828 (\"miss\") appears 1 time.\n",
            "Word 906 (\"cause\") appears 1 time.\n",
            "Word 957 (\"thought\") appears 1 time.\n",
            "Word 1021 (\"indian\") appears 1 time.\n",
            "Word 1026 (\"news\") appears 1 time.\n",
            "Word 1083 (\"opportunity\") appears 1 time.\n",
            "Word 1130 (\"engineering\") appears 1 time.\n",
            "Word 1164 (\"joke\") appears 1 time.\n",
            "Word 1173 (\"month\") appears 1 time.\n",
            "Word 1188 (\"past\") appears 1 time.\n",
            "Word 1225 (\"suspect\") appears 1 time.\n",
            "Word 1264 (\"accidental\") appears 1 time.\n",
            "Word 1265 (\"compress\") appears 1 time.\n",
            "Word 1266 (\"degree\") appears 1 time.\n",
            "Word 1308 (\"squid\") appears 1 time.\n",
            "Word 1351 (\"chief\") appears 1 time.\n",
            "Word 1383 (\"scratch\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(bow_doc_123)):\n",
        "    print(f'Word {bow_doc_123[i][0]} (\\\"{dictionary[bow_doc_123[i][0]]}\\\") appears {bow_doc_123[i][1]} time.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TF-IDF**\n",
        "\n",
        "Create tf-idf model object using models.TfidfModel on `bow_corpus` and save it to `tfidf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf = models.TfidfModel(bow_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then apply transformation to the entire corpus and call it `corpus_tfidf`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we preview TF-IDF scores for our first document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 0.09489126715998976),\n",
            " (1, 0.04122880275854039),\n",
            " (2, 0.07715428997063789),\n",
            " (3, 0.14758920597550684),\n",
            " (4, 0.10070770263942229),\n",
            " (5, 0.11385022401381809),\n",
            " (6, 0.10716872118878243),\n",
            " (7, 0.047726607296539166),\n",
            " (8, 0.820901229577695),\n",
            " (9, 0.1164666362552121),\n",
            " (10, 0.09961072060371479),\n",
            " (11, 0.06929385519173295),\n",
            " (12, 0.1316869776947954),\n",
            " (13, 0.07155540336586026),\n",
            " (14, 0.10587086007883405),\n",
            " (15, 0.07668335931854188),\n",
            " (16, 0.1225290967934336),\n",
            " (17, 0.13858883679180878),\n",
            " (18, 0.08726454060961343),\n",
            " (19, 0.035006405260232965),\n",
            " (20, 0.04539626019819227),\n",
            " (21, 0.0889926820797483),\n",
            " (22, 0.12036536133205145),\n",
            " (23, 0.10173508037814769),\n",
            " (24, 0.07255198705502106),\n",
            " (25, 0.09361235903184789),\n",
            " (26, 0.03758256619598643),\n",
            " (27, 0.11556819406164225),\n",
            " (28, 0.12876483420491122),\n",
            " (29, 0.12486610912807189),\n",
            " (30, 0.1367045012371823),\n",
            " (31, 0.05324109095911733),\n",
            " (32, 0.11934079770069406),\n",
            " (33, 0.05054406090088698),\n",
            " (34, 0.07621990407260527)]\n"
          ]
        }
      ],
      "source": [
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS1jG-vbXsWo"
      },
      "source": [
        "**Running LDA using TF-IDF**\n",
        "\n",
        "Train our lda model using gensim.models.LdaMulticore and save it to lda_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DJVJRU3Xl9u",
        "outputId": "a8594686-89cb-45b4-9adc-f154fc840762"
      },
      "outputs": [],
      "source": [
        "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the Keyword in the 10 topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lKG4Z4UX3y7",
        "outputId": "647abfab-507f-47f3-e719-b6f281a0a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.005*\"bike\" + 0.004*\"bnrca\" + 0.004*\"infante\" + 0.004*\"dog\" + 0.003*\"dod\" '\n",
            "  '+ 0.003*\"san\" + 0.003*\"motorcycle\" + 0.003*\"mile\" + 0.003*\"bmw\" + '\n",
            "  '0.003*\"computer\"'),\n",
            " (1,\n",
            "  '0.004*\"gun\" + 0.004*\"curve\" + 0.003*\"bike\" + 0.003*\"lock\" + 0.003*\"helmet\" '\n",
            "  '+ 0.003*\"version\" + 0.003*\"firearm\" + 0.003*\"make\" + 0.003*\"know\" + '\n",
            "  '0.003*\"point\"'),\n",
            " (2,\n",
            "  '0.005*\"bike\" + 0.004*\"graphic\" + 0.004*\"tank\" + 0.004*\"chuck\" + 0.003*\"gun\" '\n",
            "  '+ 0.003*\"like\" + 0.003*\"look\" + 0.003*\"buy\" + 0.003*\"value\" + '\n",
            "  '0.003*\"email\"'),\n",
            " (3,\n",
            "  '0.004*\"gun\" + 0.003*\"mode\" + 0.003*\"cdt\" + 0.003*\"child\" + '\n",
            "  '0.003*\"motorcycle\" + 0.003*\"know\" + 0.003*\"say\" + 0.003*\"make\" + '\n",
            "  '0.003*\"course\" + 0.003*\"rider\"'),\n",
            " (4,\n",
            "  '0.007*\"file\" + 0.006*\"image\" + 0.005*\"format\" + 0.004*\"graphic\" + '\n",
            "  '0.004*\"use\" + 0.004*\"bit\" + 0.004*\"behanna\" + 0.004*\"need\" + 0.003*\"know\" + '\n",
            "  '0.003*\"thanks\"'),\n",
            " (5,\n",
            "  '0.003*\"bike\" + 0.003*\"dave\" + 0.003*\"image\" + 0.003*\"gun\" + 0.003*\"use\" + '\n",
            "  '0.003*\"routine\" + 0.003*\"dog\" + 0.003*\"weapon\" + 0.003*\"say\" + '\n",
            "  '0.003*\"email\"'),\n",
            " (6,\n",
            "  '0.004*\"bike\" + 0.004*\"image\" + 0.004*\"ranck\" + 0.003*\"helmet\" + '\n",
            "  '0.003*\"speedy\" + 0.003*\"use\" + 0.003*\"bmw\" + 0.003*\"motorcycle\" + '\n",
            "  '0.003*\"tony\" + 0.003*\"john\"'),\n",
            " (7,\n",
            "  '0.004*\"law\" + 0.004*\"right\" + 0.003*\"graphic\" + 0.003*\"netcomcom\" + '\n",
            "  '0.003*\"atf\" + 0.003*\"bike\" + 0.003*\"look\" + 0.003*\"batf\" + 0.003*\"need\" + '\n",
            "  '0.003*\"good\"'),\n",
            " (8,\n",
            "  '0.005*\"wave\" + 0.004*\"split\" + 0.004*\"roby\" + 0.004*\"newsgroup\" + '\n",
            "  '0.004*\"vesa\" + 0.004*\"graphic\" + 0.004*\"program\" + 0.003*\"scott\" + '\n",
            "  '0.003*\"group\" + 0.003*\"need\"'),\n",
            " (9,\n",
            "  '0.006*\"gun\" + 0.003*\"bike\" + 0.003*\"thing\" + 0.003*\"use\" + 0.003*\"right\" + '\n",
            "  '0.003*\"just\" + 0.003*\"way\" + 0.003*\"time\" + 0.003*\"state\" + '\n",
            "  '0.003*\"criminal\"')]\n"
          ]
        }
      ],
      "source": [
        "pprint(lda_model.print_topics())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UcOPoLTScu4V",
        "S_BBNjjzc4m5",
        "c0cAeBowGUVP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "6787912cc06540c826098c2e9891f9672e6365160866aa38805d4b2fc3d28660"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
